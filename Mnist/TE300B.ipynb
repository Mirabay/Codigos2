{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TE 300B\n",
    "## Deep Learning\n",
    "## Fully Connected Deep Neural Networks\n",
    "\n",
    "#### Activity 1b: Implementing a Fully Connected Network for Kaggle ASL Dataset\n",
    "\n",
    "- Objective\n",
    "\n",
    "The aim of this part of the activity is to apply your understanding of Fully Connected Networks by implementing a multilayer network for the [Kaggle ASL (American Sign Language) dataset](https://www.kaggle.com/datasets/grassknoted/asl-alphabet). While you have been provided with a complete solution for a Fully Connected Network using Numpy for the MNIST dataset, you are encouraged to try to come up with the solution.\n",
    "\n",
    "- Instructions\n",
    "\n",
    "    This activity requires submission either individually or in teams of 3 or 4 members, and most be presented at the end of the correspoding.  While teamwork is encouraged, each member is expected to contribute individually to the assignment. The final submission should feature the best arguments and solutions from each team member. \n",
    "\n",
    "    Load and Preprocess Data: You are provided a starter code to load the data. Be sure to understand the code.\n",
    "\n",
    "    Review MNIST Notebook (Optional): Before diving into this activity, you have the option to revisit the MNIST example to refresh your understanding of how to build a Fully Connected Network using Numpy.\n",
    "\n",
    "    Start Fresh: Although you can refer to the MNIST solution at any point, try to implement the network for the ASL dataset on your own. This will reinforce your learning and understanding of the architecture and mathematics involved.\n",
    "\n",
    "    Implement Forward and Backward Pass: Write the code to perform the forward and backward passes, keeping in mind the specific challenges and characteristics of the ASL dataset.\n",
    "    \n",
    "     Design the Network: Create the architecture of the Fully Connected Network tailored for the ASL dataset. Choose the number of hidden layers, neurons, and hyperparameters judiciously.\n",
    "\n",
    "    Train the Model: Execute the training loop, ensuring to track performance metrics such as loss and accuracy.\n",
    "\n",
    "    Analyze and Document: Use Markdown cells to document in detail the choices you made in terms of architecture and hyperparameters, you may use figures, equations, etc to aid in your explanations. Include any metrics that help justify these choices and discuss the model's performance.  \n",
    "\n",
    "- Submission\n",
    "\n",
    "Show this Jupyter Notebook to your professor with your complete solution, ensuring your code is well-commented and includes Markdown cells that explain your design choices, results, and any challenges you encountered.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#################################\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_PATH = '/media/pepe/DataUbuntu/Databases/asl_data/'\n",
    "DATA_PATH = './asl_data'\n",
    "train_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_train.csv'))\n",
    "valid_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_valid.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>118</td>\n",
       "      <td>127</td>\n",
       "      <td>134</td>\n",
       "      <td>139</td>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>...</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>149</td>\n",
       "      <td>128</td>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "      <td>163</td>\n",
       "      <td>175</td>\n",
       "      <td>103</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>195</td>\n",
       "      <td>194</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>231</td>\n",
       "      <td>230</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>222</td>\n",
       "      <td>229</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>164</td>\n",
       "      <td>167</td>\n",
       "      <td>170</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>108</td>\n",
       "      <td>133</td>\n",
       "      <td>163</td>\n",
       "      <td>157</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      3     107     118     127     134     139     143     146     150   \n",
       "1      6     155     157     156     156     156     157     156     158   \n",
       "2      2     187     188     188     187     187     186     187     188   \n",
       "3      2     211     211     212     212     211     210     211     210   \n",
       "4     12     164     167     170     172     176     179     180     184   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0     153  ...       207       207       207       207       206       206   \n",
       "1     158  ...        69       149       128        87        94       163   \n",
       "2     187  ...       202       201       200       199       198       199   \n",
       "3     210  ...       235       234       233       231       230       226   \n",
       "4     185  ...        92       105       105       108       133       163   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0       206       204       203       202  \n",
       "1       175       103       135       149  \n",
       "2       198       195       194       195  \n",
       "3       225       222       229       163  \n",
       "4       157       163       164       179  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train = np.array(train_df['label'])\n",
    "y_val = np.array(valid_df['label'])\n",
    "del train_df['label']\n",
    "del valid_df['label']\n",
    "x_train = train_df.values.astype(np.float32)\n",
    "x_val = valid_df.values.astype(np.float32)\n",
    "\n",
    "Label_Encoder= LabelEncoder()\n",
    "y_train = Label_Encoder.fit_transform(y_train)\n",
    "y_val = Label_Encoder.fit_transform(y_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def split_val_test(x, y, pct=0.5, shuffle=True):\n",
    "    # Si shuffle es True, se reordenan los datos\n",
    "    if shuffle:\n",
    "        idx = np.random.permutation(len(x))  # Genera una permutaciÃ³n aleatoria de los Ã­ndices\n",
    "        x = x[idx]  # Reordena x con los Ã­ndices aleatorios\n",
    "        y = y[idx]  # Reordena y con los Ã­ndices aleatorios\n",
    "\n",
    "    # Calcula el Ã­ndice donde se dividirÃ¡n los datos\n",
    "    split_idx = int(len(x) * (pct))\n",
    "\n",
    "    # Divide los datos en dos partes en el Ã­ndice calculado\n",
    "    x_val = x[:split_idx]  # Los primeros 'split_idx' elementos se usan para la validaciÃ³n\n",
    "    y_val = y[:split_idx]  # Los primeros 'split_idx' elementos se usan para la validaciÃ³n\n",
    "    x_test = x[split_idx:]  # Los elementos restantes se usan para la prueba\n",
    "    y_test = y[split_idx:]  # Los elementos restantes se usan para la prueba\n",
    "\n",
    "    # Devuelve los conjuntos de validaciÃ³n y prueba\n",
    "    return x_val, y_val, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, y_val, x_test, y_test = split_val_test(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "### The following\n",
    "\n",
    "alphabet=list(string.ascii_lowercase)\n",
    "alphabet.remove('j')\n",
    "alphabet.remove('z')\n",
    "print(len(alphabet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(x_mean, x_std, x_data):\n",
    "    return (x_data - x_mean) / x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = x_train.mean()\n",
    "x_std = x_train.std()\n",
    "\n",
    "x_train = normalize_data(x_mean, x_std, x_train)\n",
    "x_val = normalize_data(x_mean, x_std, x_val)\n",
    "x_test = normalize_data(x_mean, x_std, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.6268384e-06, 0.99999946)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.mean(), x_train.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficar muestras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Crea una nueva figura con un tamaÃ±o de 5x5 pulgadas.\n",
    "- Muestra la imagen propocionada. 'squeeze()' se usa para eliminar las dimensiones de tamaÃ±o uno de la imagen. 'cmap=plt.get('gray')' se usa para mostrar la imagen en escala de grises.\n",
    "- Desactiva los ejes de la figura.\n",
    "- muestra la figura.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples(x_data, y_data, num_samples=24):\n",
    " # Select random indices to plot\n",
    "    idx = np.random.randint(len(y_data))\n",
    "\n",
    "    # Plot the samples\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.imshow(x_data[idx].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f'Label: {alphabet[y_data[idx]]}')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_samples(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ecuaciones para nuestro modelo\n",
    "\n",
    "\n",
    "$$z^1 = W^1 X + b^1$$\n",
    "\n",
    "$$a^1 = ReLU(z^1) $$\n",
    "\n",
    "$$z^2 = W^2 a^1 + b^2$$\n",
    "\n",
    "$$\\hat{y} = \\frac{e^{z^{2_k}}}{\\sum_j{e^{z_j}}}$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{L}(\\hat{y}^{i}, y^{i}) =  - y^{i}  \\ln(\\hat{y}^{i}) = -\\ln(\\hat{y}^i)$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{J}(w, b) =  \\frac{1}{num\\_samples} \\sum_{i=1}^{num\\_samples}-\\ln(\\hat{y}^{i})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones adicionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mini batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minibatches(mb_size, x, y, shuffle = True):\n",
    "    '''\n",
    "    x  #muestras, 784\n",
    "    y #muestras, 1\n",
    "    '''\n",
    "    assert x.shape[0] == y.shape[0], 'Error en cantidad de muestras' # Aseguramos que la cantidad de muestras sea la misma\n",
    "    total_data = x.shape[0] # Obtenemos la cantidad de muestras\n",
    "    if shuffle: \n",
    "        idxs = np.arange(total_data)\n",
    "        np.random.shuffle(idxs)\n",
    "        x = x[idxs]\n",
    "        y = y[idxs]  \n",
    "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuestra clase Linear, ReLU y Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "class np_tensor(np.ndarray): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Clase Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(): # Clase para definir una capa lineal\n",
    "    def __init__(self, input_size, output_size):\n",
    "        '''\n",
    "        Init parameters utilizando Kaiming He\n",
    "        '''\n",
    "        self.W = (np.random.randn(output_size, input_size) /np.sqrt(input_size/2)).view(np_tensor) # Inicializamos los pesos de forma aleatoria\n",
    "        self.b = np.zeros((output_size, 1)).view(np_tensor) # Inicializamos los bias en 0\n",
    "        \n",
    "    def __call__(self, X): # esta el foward de la clase lineal\n",
    "        Z= self.W @ X + self.b # Multiplicamos los pesos por la entrada y le sumamos el bias\n",
    "        return Z\n",
    "        \n",
    "    def backward(self, X, Z): # esta es la parte de backpropagation\n",
    "        \n",
    "        # Calculamos el gradiente de la entrada,\n",
    "        # la Matriz de pesos transpuesta por el gradiente de la salida\n",
    "        X.grad = self.W.T @ Z.grad \n",
    "        \n",
    "        # Calculamos el gradiente de los pesos, el gradiente \n",
    "        # de la salida por la entrada transpuesta\n",
    "        self.W.grad = Z.grad @ X.T \n",
    "        \n",
    "        # Calculamos el gradiente del bias, \n",
    "        # sumamos el gradiente de la salida\n",
    "        self.b.grad = np.sum(Z.grad, axis=1, keepdims=True) \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(): # Clase para la funciÃ³n de activaciÃ³n ReLU, debe regresar el calor maximo entre 0 y el valor de Z\n",
    "    def __call__(self, Z):\n",
    "        return np.maximum(0, Z) # Regresamos el valor maximo entre 0 y Z\n",
    "    \n",
    "    def backward(self, Z, A):\n",
    "        Z.grad = A.grad.copy() # Copiamos el gradiente de A a Z\n",
    "        Z.grad[Z < 0] = 0 # Si Z es menor a 0, el gradiente es 0\n",
    "        return Z.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential_layers():\n",
    "    def __init__(self, layers): # Inicializamos las capas\n",
    "        '''\n",
    "        layers - lista que contiene objetos de tipo Linear, ReLU\n",
    "        '''\n",
    "        self.layers = layers\n",
    "        self.x = None\n",
    "        self.outputs = {}\n",
    "\n",
    "    def __call__(self, X): # Forward de la red\n",
    "        self.x = X\n",
    "        self.outputs['l0'] = self.x #El diccionario tien como llave L0\n",
    "        for i, layer in enumerate(self.layers,1):\n",
    "          self.x=layer(self.x)\n",
    "          self.outputs['l'+str(i)] = self.x\n",
    "        return self.x # La salida de la ultima capa.\n",
    "\n",
    "    def backward(self):\n",
    "        for i in reversed(range(len(self.layers))):\n",
    "          self.layers[i].backward(self.outputs['l' + str(i)], self.outputs['l' + str(i + 1)])\n",
    "\n",
    "    def update(self, learning_rate = 1e-3):\n",
    "        for layer in self.layers:\n",
    "          if isinstance(layer, ReLU): continue\n",
    "          layer.W = layer.W - learning_rate * layer.W.grad\n",
    "          layer.b = layer.b - learning_rate * layer.b.grad\n",
    "\n",
    "    # Predicts the image\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scores if the entry for softmax\n",
    "def softmaxXEntropy(x, y):\n",
    "  # Softmax\n",
    "  exp_scores = np.exp(x)\n",
    "  sum_exp_scores = np.sum(exp_scores, axis = 0, keepdims = True)\n",
    "  probs = exp_scores/sum_exp_scores\n",
    "\n",
    "  # XEntropy\n",
    "  y_hat = probs[y.squeeze(), np.arange(x.shape[1])]\n",
    "  cost = np.mean(-np.log(y_hat))\n",
    "  probs[y.squeeze(), np.arange(x.shape[1])] -= 1\n",
    "\n",
    "  x.grad = probs\n",
    "  return probs, cost\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs, mb_size=128, learning_rate = 1e-3): # FunciÃ³n para entrenar el modelo\n",
    "    for epoch in range(epochs): # Recorremos las Ã©pocas\n",
    "        for i,(x,y) in enumerate(create_minibatches(mb_size, x_train, y_train)): # Recorremos los minibatches\n",
    "            y=y.reshape(-1,1)\n",
    "            scores = model(x.T.view(np_tensor)) # Obtenemos los scores\n",
    "            _,cost = softmaxXEntropy(scores, y) # Calculamos el costo\n",
    "            model.backward() # Backpropagation\n",
    "            model.update(learning_rate) # Actualizamos los pesos\n",
    "            \n",
    "        print(f'Epoch: {epoch} - Costo: {cost.mean()}') # Imprimimos el costo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model,x, y, mb_size): # FunciÃ³n para calcular la precisiÃ³n del modelo\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (x,y) in enumerate (create_minibatches(mb_size, x, y)): # Recorremos los minibatches\n",
    "        pred = model(x.T.view(np_tensor)) # Obtenemos las predicciones\n",
    "        correct += np.sum(np.argmax(pred, axis=0) == y.squeeze()) # Sumamos las predicciones correctas\n",
    "        total += pred.shape[1] # Sumamos el total de predicciones\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create your model and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential_layers([Linear(784, 200), ReLU(), Linear(200, 200), ReLU(), Linear(200, 24)])\n",
    "mb_size = 128\n",
    "learning_rate = 1e-3\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - Costo: 0.050419157355705436\n",
      "Epoch: 1 - Costo: 0.014802302850579853\n",
      "Epoch: 2 - Costo: 0.007665945673743035\n",
      "Epoch: 3 - Costo: 0.005008381989127569\n",
      "Epoch: 4 - Costo: 0.004759288912630424\n",
      "Epoch: 5 - Costo: 0.003152824558050127\n",
      "Epoch: 6 - Costo: 0.0024967489275462803\n",
      "Epoch: 7 - Costo: 0.0029260424468392394\n",
      "Epoch: 8 - Costo: 0.002424909223664339\n",
      "Epoch: 9 - Costo: 0.002139206522655634\n",
      "Epoch: 10 - Costo: 0.0014429727234806832\n",
      "Epoch: 11 - Costo: 0.0011480272237656235\n",
      "Epoch: 12 - Costo: 0.0012839533446975919\n",
      "Epoch: 13 - Costo: 0.0008552521232361641\n",
      "Epoch: 14 - Costo: 0.0008230789167156617\n",
      "Epoch: 15 - Costo: 0.0011305096070649264\n",
      "Epoch: 16 - Costo: 0.001216406798877986\n",
      "Epoch: 17 - Costo: 0.0010324664615788126\n",
      "Epoch: 18 - Costo: 0.0005704824660922935\n",
      "Epoch: 19 - Costo: 0.0005903191773758438\n"
     ]
    }
   ],
   "source": [
    "train(model, epochs, mb_size, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your model on Random data from your test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7986614612381484\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(model, x_test, y_test, mb_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "plot_samples() missing 1 required positional argument: 'y_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[221], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;28mlen\u001b[39m(y_test))\n\u001b[1;32m----> 2\u001b[0m \u001b[43mplot_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_test[idx]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mel valor predicho es: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malphabet[pred]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m el valor real es:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00malphabet[y_test[idx]]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: plot_samples() missing 1 required positional argument: 'y_data'"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(len(y_test))\n",
    "plot_samples(x_test[idx].reshape(28,28))\n",
    "pred = model.predict(x_test[idx].reshape(-1, 1))\n",
    "print(f'el valor predicho es: {alphabet[pred]} el valor real es:{alphabet[y_test[idx]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
