{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Neuronal MultiCapa, OOP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_images import get_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 50000\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] [[5 0 4 ... 8 4 8]]\n"
     ]
    }
   ],
   "source": [
    "# MNIST path\n",
    "mnist_path = './mnist_raw/'\n",
    "x_train_num, y_train_num, x_test_num, y_test_num = get_images(mnist_path)\n",
    "\n",
    "# Extraemos los primeros 5k datos, y los reagrupamos en 5k filas,y comlumnas como el producto flotante de 28*28 (por eso el -1)\n",
    "x_train = x_train_num[:50000].reshape(50000, -1).astype(float)\n",
    "y_train = y_train_num[:50000].reshape(50000, 1) # Extraemos 5k datos y los formatemaos en 5k filas y una sola columna.\n",
    "print(x_train.shape[0], y_train.shape[0])\n",
    "# Validation Set\n",
    "x_val = x_train_num[50000:].reshape(10000, -1).astype(float)\n",
    "y_val = y_train_num[50000:].reshape(10000, 1)\n",
    "# Set de pruebas\n",
    "x_test = x_test_num.copy().reshape(10000, -1).astype(float)\n",
    "y_test = y_test_num.copy().reshape(10000, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Hasta este punto tenemos 3 sets\n",
    "- Un set de Entrenamiento   $\\to$ Es el set mas grande y son los datos para entrenar el modelo\n",
    "- Un set de validación      $\\to$ Es para afinar el modelo y ver que tan bien esta funcionando\n",
    "- Un Set de Pruebas         $\\to$ Sera la prueba final del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33.39512885204082, 78.6661972212754, 0.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.mean(), x_train.std(), x_train.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para normalizar los datos\n",
    "### $\\frac{X_{\\text{data}}-X_{\\text{mean}}}{X_{\\text{std}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(x_mean, x_std, x_data): # Función para normalizar los datos\n",
    "    return (x_data - x_mean) / x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = x_train.mean() # sacamos la media\n",
    "x_std = x_train.std()   # sacamos el std\n",
    "\n",
    "# Normalizamos nuestros Set's de datos\n",
    "x_train = normalise(x_mean, x_std, x_train)\n",
    "x_val = normalise(x_mean, x_std, x_val)\n",
    "x_test = normalise(x_mean, x_std, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-9.646705203355238e-18, 0.9999999999999997)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.mean(), x_train.std() # Nos quedamos con una media muy pequeña y un STD sercano a 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficar muestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_number(image): # Grafica un numero \n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image.squeeze(), cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La imagen muestreada representa un: 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grafica un numero random\n",
    "rnd_idx = np.random.randint(len(y_test))\n",
    "print(f'La imagen muestreada representa un: {y_test[rnd_idx, 0]}')\n",
    "plot_number(x_test_num[rnd_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar como nos da una imagen aleatoria y el resultado correcto de esta imagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ecuaciones para nuestro modelo\n",
    "\n",
    "\n",
    "$$z^1 = W^1 X + b^1$$\n",
    "\n",
    "$$a^1 = ReLU(z^1) $$\n",
    "\n",
    "$$z^2 = W^2 a^1 + b^2$$\n",
    "\n",
    "$$\\hat{y} = \\frac{e^{z^{2_k}}}{\\sum_j{e^{z_j}}}$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{L}(\\hat{y}^{i}, y^{i}) =  - y^{i}  \\ln(\\hat{y}^{i}) = -\\ln(\\hat{y}^i)$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{J}(w, b) =  \\frac{1}{num\\_samples} \\sum_{i=1}^{num\\_samples}-\\ln(\\hat{y}^{i})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones adicionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mini batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minibatches(mb_size, x, y, shuffle = True):\n",
    "    '''\n",
    "    x  #muestras, 784\n",
    "    y #muestras, 1\n",
    "    '''\n",
    "    print(x.shape[0], y.shape[0])\n",
    "    assert x.shape[0] == y.shape[0], 'Error en cantidad de muestras' # Aseguramos que la cantidad de muestras sea la misma\n",
    "    total_data = x.shape[0] # Obtenemos la cantidad de muestras\n",
    "    if shuffle: \n",
    "        idxs = np.arange(total_data)\n",
    "        np.random.shuffle(idxs)\n",
    "        x = x[idxs]\n",
    "        y = y[idxs]  \n",
    "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta jalada no sirve de nada, la sacamos de internet\n",
    "def init_parameters(input_size,neurons):\n",
    "    \n",
    "    W1 = np.random.randn(neurons[0], input_size)*0.001\n",
    "    b1 = np.zeros((neurons[0],1))\n",
    "    \n",
    "    W2 = np.random.randn(neurons[1],neurons[0]*0.001)\n",
    "    b2 = np.zeros((neurons[1],1))\n",
    "    \n",
    "    return{'W1':W1,'b1':b1 ,'W2':W2,'b2':b2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuestra clase Linear, ReLU y Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class np_tensor(np.ndarray): pass # Clase para definir un tensor, que es una matriz de numpy, pero con un nombre para poder identificarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0, 0])\n",
    "b = a.view(np_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.np_tensor"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np_tensor([ True,  True])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a is b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Clase Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Linear(): # Clase para definir una capa lineal\n",
    "    def __init__(self, input_size, output_size):\n",
    "        '''\n",
    "        Init parameters utilizando Kaiming He\n",
    "        '''\n",
    "        self.W = (np.random.randn(output_size, input_size) /np.sqrt(input_size/2)).view(np_tensor) # Inicializamos los pesos de forma aleatoria\n",
    "        self.b = np.zeros((output_size, 1)).view(np_tensor) # Inicializamos los bias en 0\n",
    "        \n",
    "    def __call__(self, X): # esta el foward de la clase lineal\n",
    "        Z= self.W @ X + self.b # Multiplicamos los pesos por la entrada y le sumamos el bias\n",
    "        return Z\n",
    "        \n",
    "    def backward(self, X, Z): # esta es la parte de backpropagation\n",
    "        X.grad = self.W.T @ Z.grad # Calculamos el gradiente de la entrada\n",
    "        self.W.grad = Z.grad @ X.T # Calculamos el gradiente de los pesos\n",
    "        self.b.grad = np.sum(Z.grad, axis=1, keepdims=True) # Calculamos el gradiente del bias\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class ReLU(): # Clase para la función de activación ReLU, debe regresar el calor maximo entre 0 y el valor de Z\n",
    "    def __call__(self, Z):\n",
    "        return np.maximum(0, Z) # Regresamos el valor maximo entre 0 y Z\n",
    "    \n",
    "    def backward(self, Z, A):\n",
    "        Z.grad = A.grad.copy() # Copiamos el gradiente de A a Z\n",
    "        Z.grad[Z < 0] = 0 # Si Z es menor a 0, el gradiente es 0\n",
    "        return Z.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Sequential_layers():\n",
    "    def __init__(self, layers): # Inicializamos las capas\n",
    "        '''\n",
    "        layers - lista que contiene objetos de tipo Linear, ReLU\n",
    "        '''\n",
    "        self.layers = layers\n",
    "        self.x = None\n",
    "        self.outputs = {}\n",
    "\n",
    "    def __call__(self, X): # Forward de la red\n",
    "        self.x = X\n",
    "        self.outputs['l0'] = self.x #El diccionario tien como llave L0\n",
    "        for i, layer in enumerate(self.layers,1):\n",
    "          self.x=layer(self.x)\n",
    "          self.outputs['l'+str(i)] = self.x\n",
    "        return self.x # La salida de la ultima capa.\n",
    "\n",
    "    def backward(self): # Backward de la red\n",
    "        # Vamos a recorrer las capas en un sentido contrario\n",
    "        for i in reversed(range(len(self.layers))):\n",
    "          self.layers[i].backward(self.outputs['l'+str(i),self.outputs['l'+ str(i+1)]]) # Llamamos a la función backward de cada capa\n",
    "   \n",
    "        \n",
    "\n",
    "    def update(self, learning_rate = 1e-3): # usalmente este learning rate funciona bien\n",
    "        for layer in self.layers: # Vamos a recorrer las capas\n",
    "          if isinstance(layer,ReLU): continue # Si la capa es de tipo ReLU, continuamos\n",
    "          layer.W = layer.W - learning_rate * layer.W.grad\n",
    "          layer.b = layer.b - learning_rate * layer.b.grad\n",
    "\n",
    "    def predict(self, X): # Deberia de predecir la salida de la ultima capa\n",
    "        \n",
    "        pass  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def softmaxXEntropy(x, y):\n",
    "    # Softmax\n",
    "    exp_scores = np.exp(x) # Exponenciamos los scores\n",
    "    sum_exp_scores = np.sum(exp_scores, axis=0) # Sumamos los scores\n",
    "    probs = exp_scores / sum_exp_scores # Calculamos las probabilidades\n",
    "    \n",
    "    # Cross entropy\n",
    "    y_hat = probs[y, np.arange(x.shape[1])] # Calculamos la probabilidad de la clase correcta\n",
    "    loss = -np.log(y_hat) # Calculamos el logaritmo de la probabilidad\n",
    "    return probs, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train(model, epochs, mb_size=128, learning_rate = 1e-3): # Función para entrenar el modelo\n",
    "    for epoch in range(epochs): # Recorremos las épocas\n",
    "        for i,(x,y) in enumerate(create_minibatches(mb_size, x_train, y_train)): # Recorremos los minibatches\n",
    "            scores = model(x.T.view(np_tensor)) # Obtenemos los scores\n",
    "            _,cost = softmaxXEntropy(scores, y) # Calculamos el costo\n",
    "            model.backward() # Backpropagation\n",
    "            model.update(learning_rate) # Actualizamos los pesos\n",
    "            \n",
    "        print(f'Epoch: {epoch} - Costo: {cost.mean()}') # Imprimimos el costo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def accuracy(model,x, y, mb_size): # Función para calcular la precisión del modelo\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (x,y) in enumerate (create_minibatches(mb_size, x, y)): # Recorremos los minibatches\n",
    "        pred = model(x.view(np_tensor)) # Obtenemos las predicciones\n",
    "        correct += np.sum(np.argmax(pred, axis=0) == y.squeeze()) # Sumamos las predicciones correctas\n",
    "        total += pred.shape[1] # Sumamos el total de predicciones\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential_layers([Linear(784, 200), ReLU(), Linear(200, 200), ReLU(), Linear(200, 10)])\n",
    "mb_size = 512\n",
    "learning_rate = 1e-4\n",
    "epochs = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 50000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'np_tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmb_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[45], line 6\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, epochs, mb_size, learning_rate)\u001b[0m\n\u001b[0;32m      4\u001b[0m     scores \u001b[38;5;241m=\u001b[39m model(x\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mview(np_tensor)) \u001b[38;5;66;03m# Obtenemos los scores\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     _,cost \u001b[38;5;241m=\u001b[39m softmaxXEntropy(scores, y) \u001b[38;5;66;03m# Calculamos el costo\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     model\u001b[38;5;241m.\u001b[39mupdate(learning_rate) \u001b[38;5;66;03m# Actualizamos los pesos\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Costo: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcost\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[55], line 21\u001b[0m, in \u001b[0;36mSequential_layers.backward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;66;03m# Backward de la red\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# Vamos a recorrer las capas en un sentido contrario\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers))):\n\u001b[1;32m---> 21\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[i]\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m) \u001b[38;5;66;03m# Llamamos a la función backward de cada capa\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml0\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mgrad\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'np_tensor'"
     ]
    }
   ],
   "source": [
    "train(model, epochs, mb_size, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Error en cantidad de muestras",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmb_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[22], line 3\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, epochs, mb_size, learning_rate)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(model, epochs, mb_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-3\u001b[39m): \u001b[38;5;66;03m# Función para entrenar el modelo\u001b[39;00m\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs): \u001b[38;5;66;03m# Recorremos las épocas\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i,(x,y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mcreate_minibatches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmb_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m): \u001b[38;5;66;03m# Recorremos los minibatches\u001b[39;00m\n\u001b[0;32m      4\u001b[0m             scores \u001b[38;5;241m=\u001b[39m model(x\u001b[38;5;241m.\u001b[39mview(np_tensor)) \u001b[38;5;66;03m# Obtenemos los scores\u001b[39;00m\n\u001b[0;32m      5\u001b[0m             _,cost \u001b[38;5;241m=\u001b[39m softmaxXEntropy(scores, y) \u001b[38;5;66;03m# Calculamos el costo\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m, in \u001b[0;36mcreate_minibatches\u001b[1;34m(mb_size, x, y, shuffle)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_minibatches\u001b[39m(mb_size, x, y, shuffle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    x  #muestras, 784\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    y #muestras, 1\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError en cantidad de muestras\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      7\u001b[0m     total_data \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle: \n",
      "\u001b[1;31mAssertionError\u001b[0m: Error en cantidad de muestras"
     ]
    }
   ],
   "source": [
    "train(model, epochs, mb_size, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "accuracy() missing 1 required positional argument: 'mb_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43maccuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmb_size\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: accuracy() missing 1 required positional argument: 'mb_size'"
     ]
    }
   ],
   "source": [
    "print(accuracy(x_test, y_test, mb_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(len(y_test))\n",
    "plot_number(x_test_num[idx])\n",
    "pred = model.predict(x_test[idx].reshape(-1, 1))\n",
    "print(f'el valor predicho es: {pred}, el valor real es:{y_test[idx][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [33, 44, 555, 666]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in reversed(range(len(a))):\n",
    "    print(a[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
